{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/hrishikesh/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie_reviews', 'cmudict', 'gutenberg', 'names', 'inaugural', 'gazetteers', 'genesis.zip', 'omw.zip', 'words.zip', 'wordnet_ic', 'wordnet_ic.zip', 'wordnet', 'words', 'genesis', 'omw', 'twitter_samples', 'twitter_samples.zip', 'treebank.zip', 'shakespeare.zip', 'inaugural.zip', 'names.zip', 'gazetteers.zip', 'shakespeare', 'stopwords', 'stopwords.zip', 'cmudict.zip', 'wordnet.zip', 'movie_reviews.zip', 'gutenberg.zip', 'treebank']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet = nltk.corpus.gutenberg.words('shakespeare-caesar.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Julius', 'Caesar', ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The Tragedie of Julius Caesar by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Flauius , Murellus , and certaine Commoners ouer the Stage . Flauius . Hence : home you idle Creatures , get you home : Is this a Holiday ? What , know you not ( Being Mechanicall ) you ought not walke Vpon a labouring day , without the signe Of your Profession ? Speake , what Trade art thou ? Car . Why Sir , a Carpenter Mur . Where is thy Leather Apron , and thy Rule ? What dost thou with thy best Apparrell on ? You sir , what Trade are you ? Cobl . Truely Sir , in respect of a fine Workman , I am but as you would say , a Cobler Mur . But what Trade art thou ? Answer me directly Cob . A Trade Sir , that I hope I may vse , with a safe Conscience , which is indeed Sir , a Mender of bad soules Fla . What Trade thou knaue ? Thou naughty knaue , what Trade ? Cobl . Nay I beseech you Sir , be not out with me : yet if you be out Sir , I can mend you Mur . What mean ' st thou by that ? Mend mee , thou sawcy Fellow ? Cob . Why sir , Cobble you Fla . Thou art a Cobler , art thou ? Cob . Truly sir , all that I liue by , is with the Aule : I meddle with no Tradesmans matters , nor womens matters ; but withal I am indeed Sir , a Surgeon to old shooes : when they are in great danger , I recouer them . As proper men as euer trod vpon Neats Leather , haue gone vpon my handy - worke Fla . But wherefore art not in thy Shop to day ? Why do ' st thou leade these men about the streets ? Cob . Truly sir , to weare out their shooes , to get my selfe into more worke . But indeede sir , we make Holyday to see Caesar , and to reioyce in his Triumph Mur . Wherefore reioyce ? What Conquest brings he home ? What Tributaries follow him to Rome , To grace in Captiue bonds his Chariot Wheeles ? You Blockes , you stones , you worse then senslesse things : O you hard hearts , you cruell men of Rome , Knew you not Pompey many a time and oft ? Haue you climb ' d vp to Walles and Battlements , To Towres and Windowes ? Yea , to Chimney tops , Your Infants in your Armes , and there haue sate The liue - long day , with patient expectation , To see great Pompey passe the streets of Rome : And when you saw his Chariot but appeare , Haue you "
     ]
    }
   ],
   "source": [
    "for word in hamlet[:500]:\n",
    "    print(word, sep=' ',end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet = \"\"\"Lorem ipsum dolor sit amet, consectetuer adipiscing elit. \n",
    "            Aenean commodo ligula eget dolor. Aenean massa. \n",
    "            Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. \n",
    "            Donec quam felis, ultricies nec, pellentesque eu, pretium quis, sem. \n",
    "            Nulla consequat massa quis enim. Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu. \n",
    "            In enim justo, rhoncus ut, imperdiet a, venenatis vitae, justo. \n",
    "            Nullam dictum felis eu pede mollis pretium. Integer tincidunt. \n",
    "            Cras dapibus. Vivamus elementum semper nisi. \n",
    "            Aenean vulputate eleifend tellus. Aenean leo ligula, porttitor eu, consequat vitae, eleifend ac, enim. \n",
    "            Aliquam lorem ante, dapibus in, viverra quis, feugiat a, tellus. \n",
    "            Phasellus viverra nulla ut metus varius laoreet. Quisque rutrum. Aenean imperdiet. \n",
    "            Etiam ultricies nisi vel augue. Curabitur ullamcorper ultricies nisi. Nam eget dui. Etiam rhoncus. \n",
    "            Maecenas tempus, tellus eget condimentum rhoncus, sem quam semper libero, sit amet adipiscing sem neque sed ipsum. Nam quam nunc, blandit vel, luctus pulvinar, hendrerit id, lorem. \n",
    "            Maecenas nec odio et ante tincidunt tempus. Donec vitae sapien ut libero venenatis faucibus. \n",
    "            Nullam quis ante. Etiam sit amet orci eget eros faucibus tincidunt. Duis leo. Sed fringilla mauris sit amet nibh. \n",
    "            Donec sodales sagittis magna. Sed consequat, leo eget bibendum sodales, augue velit cursus nunc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_tokens = word_tokenize(snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem',\n",
       " 'ipsum',\n",
       " 'dolor',\n",
       " 'sit',\n",
       " 'amet',\n",
       " ',',\n",
       " 'consectetuer',\n",
       " 'adipiscing',\n",
       " 'elit',\n",
       " '.',\n",
       " 'Aenean',\n",
       " 'commodo',\n",
       " 'ligula',\n",
       " 'eget',\n",
       " 'dolor',\n",
       " '.',\n",
       " 'Aenean',\n",
       " 'massa',\n",
       " '.',\n",
       " 'Cum',\n",
       " 'sociis',\n",
       " 'natoque',\n",
       " 'penatibus',\n",
       " 'et',\n",
       " 'magnis',\n",
       " 'dis',\n",
       " 'parturient',\n",
       " 'montes',\n",
       " ',',\n",
       " 'nascetur',\n",
       " 'ridiculus',\n",
       " 'mus',\n",
       " '.',\n",
       " 'Donec',\n",
       " 'quam',\n",
       " 'felis',\n",
       " ',',\n",
       " 'ultricies',\n",
       " 'nec',\n",
       " ',',\n",
       " 'pellentesque',\n",
       " 'eu',\n",
       " ',',\n",
       " 'pretium',\n",
       " 'quis',\n",
       " ',',\n",
       " 'sem',\n",
       " '.',\n",
       " 'Nulla',\n",
       " 'consequat',\n",
       " 'massa',\n",
       " 'quis',\n",
       " 'enim',\n",
       " '.',\n",
       " 'Donec',\n",
       " 'pede',\n",
       " 'justo',\n",
       " ',',\n",
       " 'fringilla',\n",
       " 'vel',\n",
       " ',',\n",
       " 'aliquet',\n",
       " 'nec',\n",
       " ',',\n",
       " 'vulputate',\n",
       " 'eget',\n",
       " ',',\n",
       " 'arcu',\n",
       " '.',\n",
       " 'In',\n",
       " 'enim',\n",
       " 'justo',\n",
       " ',',\n",
       " 'rhoncus',\n",
       " 'ut',\n",
       " ',',\n",
       " 'imperdiet',\n",
       " 'a',\n",
       " ',',\n",
       " 'venenatis',\n",
       " 'vitae',\n",
       " ',',\n",
       " 'justo',\n",
       " '.',\n",
       " 'Nullam',\n",
       " 'dictum',\n",
       " 'felis',\n",
       " 'eu',\n",
       " 'pede',\n",
       " 'mollis',\n",
       " 'pretium',\n",
       " '.',\n",
       " 'Integer',\n",
       " 'tincidunt',\n",
       " '.',\n",
       " 'Cras',\n",
       " 'dapibus',\n",
       " '.',\n",
       " 'Vivamus',\n",
       " 'elementum',\n",
       " 'semper',\n",
       " 'nisi',\n",
       " '.',\n",
       " 'Aenean',\n",
       " 'vulputate',\n",
       " 'eleifend',\n",
       " 'tellus',\n",
       " '.',\n",
       " 'Aenean',\n",
       " 'leo',\n",
       " 'ligula',\n",
       " ',',\n",
       " 'porttitor',\n",
       " 'eu',\n",
       " ',',\n",
       " 'consequat',\n",
       " 'vitae',\n",
       " ',',\n",
       " 'eleifend',\n",
       " 'ac',\n",
       " ',',\n",
       " 'enim',\n",
       " '.',\n",
       " 'Aliquam',\n",
       " 'lorem',\n",
       " 'ante',\n",
       " ',',\n",
       " 'dapibus',\n",
       " 'in',\n",
       " ',',\n",
       " 'viverra',\n",
       " 'quis',\n",
       " ',',\n",
       " 'feugiat',\n",
       " 'a',\n",
       " ',',\n",
       " 'tellus',\n",
       " '.',\n",
       " 'Phasellus',\n",
       " 'viverra',\n",
       " 'nulla',\n",
       " 'ut',\n",
       " 'metus',\n",
       " 'varius',\n",
       " 'laoreet',\n",
       " '.',\n",
       " 'Quisque',\n",
       " 'rutrum',\n",
       " '.',\n",
       " 'Aenean',\n",
       " 'imperdiet',\n",
       " '.',\n",
       " 'Etiam',\n",
       " 'ultricies',\n",
       " 'nisi',\n",
       " 'vel',\n",
       " 'augue',\n",
       " '.',\n",
       " 'Curabitur',\n",
       " 'ullamcorper',\n",
       " 'ultricies',\n",
       " 'nisi',\n",
       " '.',\n",
       " 'Nam',\n",
       " 'eget',\n",
       " 'dui',\n",
       " '.',\n",
       " 'Etiam',\n",
       " 'rhoncus',\n",
       " '.',\n",
       " 'Maecenas',\n",
       " 'tempus',\n",
       " ',',\n",
       " 'tellus',\n",
       " 'eget',\n",
       " 'condimentum',\n",
       " 'rhoncus',\n",
       " ',',\n",
       " 'sem',\n",
       " 'quam',\n",
       " 'semper',\n",
       " 'libero',\n",
       " ',',\n",
       " 'sit',\n",
       " 'amet',\n",
       " 'adipiscing',\n",
       " 'sem',\n",
       " 'neque',\n",
       " 'sed',\n",
       " 'ipsum',\n",
       " '.',\n",
       " 'Nam',\n",
       " 'quam',\n",
       " 'nunc',\n",
       " ',',\n",
       " 'blandit',\n",
       " 'vel',\n",
       " ',',\n",
       " 'luctus',\n",
       " 'pulvinar',\n",
       " ',',\n",
       " 'hendrerit',\n",
       " 'id',\n",
       " ',',\n",
       " 'lorem',\n",
       " '.',\n",
       " 'Maecenas',\n",
       " 'nec',\n",
       " 'odio',\n",
       " 'et',\n",
       " 'ante',\n",
       " 'tincidunt',\n",
       " 'tempus',\n",
       " '.',\n",
       " 'Donec',\n",
       " 'vitae',\n",
       " 'sapien',\n",
       " 'ut',\n",
       " 'libero',\n",
       " 'venenatis',\n",
       " 'faucibus',\n",
       " '.',\n",
       " 'Nullam',\n",
       " 'quis',\n",
       " 'ante',\n",
       " '.',\n",
       " 'Etiam',\n",
       " 'sit',\n",
       " 'amet',\n",
       " 'orci',\n",
       " 'eget',\n",
       " 'eros',\n",
       " 'faucibus',\n",
       " 'tincidunt',\n",
       " '.',\n",
       " 'Duis',\n",
       " 'leo',\n",
       " '.',\n",
       " 'Sed',\n",
       " 'fringilla',\n",
       " 'mauris',\n",
       " 'sit',\n",
       " 'amet',\n",
       " 'nibh',\n",
       " '.',\n",
       " 'Donec',\n",
       " 'sodales',\n",
       " 'sagittis',\n",
       " 'magna',\n",
       " '.',\n",
       " 'Sed',\n",
       " 'consequat',\n",
       " ',',\n",
       " 'leo',\n",
       " 'eget',\n",
       " 'bibendum',\n",
       " 'sodales',\n",
       " ',',\n",
       " 'augue',\n",
       " 'velit',\n",
       " 'cursus',\n",
       " 'nunc',\n",
       " '.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snippet_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in snippet_tokens:\n",
    "    dist[word.lower()]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 32, ',': 31, 'eget': 6, 'aenean': 5, 'sit': 4, 'amet': 4, 'donec': 4, 'quis': 4, 'lorem': 3, 'quam': 3, ...})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_top = dist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 32),\n",
       " (',', 31),\n",
       " ('eget', 6),\n",
       " ('aenean', 5),\n",
       " ('sit', 4),\n",
       " ('amet', 4),\n",
       " ('donec', 4),\n",
       " ('quis', 4),\n",
       " ('lorem', 3),\n",
       " ('quam', 3)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
